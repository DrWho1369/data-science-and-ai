<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 8 - Autoencoders with Keras</title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header class="hero">
        <h1>AML Lab 8 - Autoencoders with Keras</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">‚Üê Back to Homepage</a>

        <section id="lab8">
            <h2>üß† Lab 8: Autoencoders with Keras</h2>
            <p><strong>Autoencoders</strong> are a type of <strong>neural network</strong> used for <strong>unsupervised learning</strong>. They aim to learn <strong>efficient data representations</strong> by compressing input data into a <strong>latent space</strong> and then reconstructing it. They are widely used for <strong>feature learning, dimensionality reduction, denoising, and anomaly detection</strong>.</p>
        
            <h3>üìå Loading and Preprocessing the MNIST Dataset</h3>
            <p>We will use the <strong>MNIST dataset</strong>, a collection of <strong>handwritten digits (0-9)</strong>, to train our autoencoder. The dataset consists of <strong>grayscale images of size 28x28 pixels</strong>.</p>
            <pre><code>
import tensorflow as tf
from tensorflow.keras.datasets import mnist
import numpy as np

# Load dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize pixel values to the range [0,1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Flatten images to 1D vectors (28x28 = 784 pixels)
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>Each MNIST image is <strong>28x28 pixels</strong>, but we <strong>flatten it into a 784-dimensional vector</strong> to feed into a fully connected neural network.</li>
                <li>We <strong>normalize pixel values</strong> to range <strong>0-1</strong> to stabilize training.</li>
                <li>Since autoencoders use <strong>self-supervised learning</strong>, we train the model using the <strong>same input and output data</strong>.</li>
            </ul>
        
            <h3>üìå Building the Autoencoder Model</h3>
            <p>The <strong>encoder</strong> compresses the input into a <strong>low-dimensional representation</strong>, while the <strong>decoder</strong> reconstructs the original input.</p>
            <pre><code>
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input

# Define autoencoder model
input_size = 784  # Input layer (flattened image)

# Encoder
input_img = Input(shape=(input_size,))
hidden_1 = Dense(128, activation='relu')(input_img)  # First hidden layer
code = Dense(32, activation='relu')(hidden_1)  # Latent representation

# Decoder
hidden_2 = Dense(128, activation='relu')(code)
output_img = Dense(input_size, activation='sigmoid')(hidden_2)

# Model definition
autoencoder = Model(input_img, output_img)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>The <strong>encoder</strong> compresses the <strong>784-dimensional input</strong> into a <strong>32-dimensional latent representation</strong>.</li>
                <li>The <strong>decoder</strong> reconstructs the original <strong>784-dimensional image</strong> using two dense layers.</li>
                <li><strong>ReLU activation</strong> is used in hidden layers to introduce <strong>non-linearity</strong>.</li>
                <li><strong>Sigmoid activation</strong> is used in the output layer to restrict pixel values between <strong>0 and 1</strong>.</li>
                <li><strong>Binary cross-entropy</strong> is used as the loss function because we are reconstructing pixel intensities.</li>
            </ul>
        
            <h3>üìå Training the Autoencoder</h3>
            <p>Since the autoencoder is <strong>self-supervised</strong>, the input and output data are identical.</p>
            <pre><code>
autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, validation_data=(x_test, x_test))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>Training runs for <strong>10 epochs</strong>, meaning the dataset passes through the network <strong>10 times</strong>.</li>
                <li>A <strong>batch size of 256</strong> means the model processes <strong>256 images per update step</strong>.</li>
                <li>We validate performance on the <strong>test set</strong> to check generalization.</li>
            </ul>
        
            <h3>üìå Denoising Autoencoder</h3>
            <p>A <strong>denoising autoencoder</strong> removes noise from images by learning to reconstruct the original clean version.</p>
            <pre><code>
def add_noise(data, noise_factor=0.4):
    noisy_data = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
    return np.clip(noisy_data, 0., 1.)  # Ensure values remain between 0 and 1

# Generate noisy images
x_train_noisy = add_noise(x_train)
x_test_noisy = add_noise(x_test)

# Train denoising autoencoder
autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=256, validation_data=(x_test_noisy, x_test))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>We <strong>add Gaussian noise</strong> to images but <strong>clip values</strong> between <strong>0 and 1</strong>.</li>
                <li>The model is trained to <strong>map noisy images back to their original clean versions</strong>.</li>
                <li>Denoising autoencoders learn <strong>robust feature representations</strong>, making them useful for <strong>image restoration and signal processing</strong>.</li>
            </ul>
        
            <h3>üìå Summary</h3>
            <ul>
                <li>Built an <strong>autoencoder</strong> to learn a compressed representation of data.</li>
                <li>Explored <strong>denoising autoencoders</strong> for cleaning noisy images.</li>
                <li>Used <strong>self-supervised learning</strong>, where inputs and outputs are identical.</li>
            </ul>
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
