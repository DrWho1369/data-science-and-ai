<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 8 - Autoencoders with Keras</title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header>
        <h1>AML Lab 8 - Autoencoders with Keras</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">‚Üê Back to Homepage</a>

        <section id="lab8">
            <h2>üß† Lab 8: Autoencoders with Keras</h2>
            <p><strong>Autoencoders</strong> are a type of <strong>neural network</strong> used for **unsupervised learning**. They aim to learn **efficient data representations** by compressing input data into a **latent space** and then reconstructing it. They are widely used for **feature learning, dimensionality reduction, denoising, and anomaly detection**.</p>
        
            <h3>üìå Loading and Preprocessing the MNIST Dataset</h3>
            <p>We will use the **MNIST dataset**, a collection of **handwritten digits (0-9)**, to train our autoencoder. The dataset consists of **grayscale images of size 28x28 pixels**.</p>
            <pre><code>
import tensorflow as tf
from tensorflow.keras.datasets import mnist
import numpy as np

# Load dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize pixel values to the range [0,1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Flatten images to 1D vectors (28x28 = 784 pixels)
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>Each MNIST image is **28x28 pixels**, but we **flatten it into a 784-dimensional vector** to feed into a fully connected neural network.</li>
                <li>We **normalize pixel values** to range **0-1** to stabilize training.</li>
                <li>Since autoencoders use **self-supervised learning**, we train the model using the **same input and output data**.</li>
            </ul>
        
            <h3>üìå Building the Autoencoder Model</h3>
            <p>The **encoder** compresses the input into a **low-dimensional representation**, while the **decoder** reconstructs the original input.</p>
            <pre><code>
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input

# Define autoencoder model
input_size = 784  # Input layer (flattened image)

# Encoder
input_img = Input(shape=(input_size,))
hidden_1 = Dense(128, activation='relu')(input_img)  # First hidden layer
code = Dense(32, activation='relu')(hidden_1)  # Latent representation

# Decoder
hidden_2 = Dense(128, activation='relu')(code)
output_img = Dense(input_size, activation='sigmoid')(hidden_2)

# Model definition
autoencoder = Model(input_img, output_img)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>The **encoder** compresses the **784-dimensional input** into a **32-dimensional latent representation**.</li>
                <li>The **decoder** reconstructs the original **784-dimensional image** using two dense layers.</li>
                <li><strong>ReLU activation</strong> is used in hidden layers to introduce **non-linearity**.</li>
                <li><strong>Sigmoid activation</strong> is used in the output layer to restrict pixel values between **0 and 1**.</li>
                <li><strong>Binary cross-entropy</strong> is used as the loss function because we are reconstructing pixel intensities.</li>
            </ul>
        
            <h3>üìå Training the Autoencoder</h3>
            <p>Since the autoencoder is **self-supervised**, the input and output data are identical.</p>
            <pre><code>
autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, validation_data=(x_test, x_test))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>Training runs for **10 epochs**, meaning the dataset passes through the network **10 times**.</li>
                <li>A **batch size of 256** means the model processes **256 images per update step**.</li>
                <li>We validate performance on the **test set** to check generalization.</li>
            </ul>
        
            <h3>üìå Denoising Autoencoder</h3>
            <p>A **denoising autoencoder** removes noise from images by learning to reconstruct the original clean version.</p>
            <pre><code>
def add_noise(data, noise_factor=0.4):
    noisy_data = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
    return np.clip(noisy_data, 0., 1.)  # Ensure values remain between 0 and 1

# Generate noisy images
x_train_noisy = add_noise(x_train)
x_test_noisy = add_noise(x_test)

# Train denoising autoencoder
autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=256, validation_data=(x_test_noisy, x_test))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>We **add Gaussian noise** to images but **clip values** between **0 and 1**.</li>
                <li>The model is trained to **map noisy images back to their original clean versions**.</li>
                <li>Denoising autoencoders learn **robust feature representations**, making them useful for **image restoration and signal processing**.</li>
            </ul>
        
            <h3>üìå Summary</h3>
            <ul>
                <li>Built an **autoencoder** to learn a compressed representation of data.</li>
                <li>Explored **denoising autoencoders** for cleaning noisy images.</li>
                <li>Used **self-supervised learning**, where inputs and outputs are identical.</li>
            </ul>
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
