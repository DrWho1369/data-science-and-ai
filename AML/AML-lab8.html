<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 8 - Autoencoders with Keras</title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header>
        <h1>AML Lab 8 - Autoencoders with Keras</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">‚Üê Back to Homepage</a>

        <section id="lab8">
            <h2>üß† Lab 8: Autoencoders with Keras</h2>
            <p>Autoencoders are a type of <strong>neural network</strong> used in <strong>unsupervised learning</strong>. They are designed to <strong>learn efficient representations of data</strong> by compressing the input into a <strong>latent representation</strong> and then reconstructing it. Autoencoders are widely used for <strong>feature learning, dimensionality reduction, denoising, and anomaly detection</strong>.</p>
        
            <h3>üìå Loading and Preprocessing the MNIST Dataset</h3>
            <p>We use the <strong>MNIST dataset</strong>, which consists of <strong>handwritten digits (0-9)</strong>, to train our autoencoder. The dataset contains <strong>grayscale images</strong> of size <strong>28x28 pixels</strong>.</p>
            <pre><code>
import tensorflow as tf
from tensorflow.keras.datasets import mnist
import numpy as np

# Load dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize pixel values to the [0,1] range
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Flatten images to 1D vectors (28x28 = 784 pixels)
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))

print(x_train.shape)  # Expected: (60000, 784)
print(x_test.shape)   # Expected: (10000, 784)
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>The MNIST dataset contains <strong>60,000 training images</strong> and <strong>10,000 test images</strong>.</li>
                    <li>Each image is <strong>28x28 pixels</strong>, but we <strong>flatten</strong> it into a <strong>784-dimensional vector</strong> (1D array) for input to a neural network.</li>
                    <li>We <strong>normalize</strong> pixel values to a <strong>0-1 range</strong> to improve model training stability.</li>
                </ul>
            </p>
        
            <h3>üìå Building the Autoencoder Model</h3>
            <p>The <strong>encoder</strong> compresses the input into a <strong>low-dimensional representation</strong>, and the <strong>decoder</strong> reconstructs it back to the original format.</p>
            <pre><code>
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input

# Define autoencoder model
input_size = 784  # Input layer (flattened image)

# Encoder
input_img = Input(shape=(input_size,))
hidden_1 = Dense(128, activation='relu')(input_img)  # First hidden layer
code = Dense(32, activation='relu')(hidden_1)  # Latent representation

# Decoder
hidden_2 = Dense(128, activation='relu')(code)
output_img = Dense(input_size, activation='sigmoid')(hidden_2)

# Model definition
autoencoder = Model(input_img, output_img)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>The <strong>encoder</strong> reduces the <strong>784-dimensional</strong> input into a <strong>32-dimensional latent representation</strong>.</li>
                    <li>The <strong>decoder</strong> reconstructs the original input using <strong>two dense layers</strong>.</li>
                    <li><strong>ReLU activation</strong> is used in hidden layers to introduce <strong>non-linearity</strong>.</li>
                    <li><strong>Sigmoid activation</strong> is used in the output layer to keep pixel values between <strong>0 and 1</strong>.</li>
                    <li>We use <strong>binary cross-entropy</strong> as the loss function because we are reconstructing pixel values.</li>
                </ul>
            </p>
        
            <h3>üìå Training the Autoencoder</h3>
            <p>We train the autoencoder using the <strong>original images as both inputs and targets</strong> (self-supervised learning).</p>
            <pre><code>
autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, validation_data=(x_test, x_test))
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>The autoencoder is trained for <strong>10 epochs</strong>, meaning the dataset passes through the network <strong>10 times</strong>.</li>
                    <li>A <strong>batch size of 256</strong> means the model processes <strong>256 images at a time</strong> before updating weights.</li>
                    <li>We validate performance on the <strong>test set</strong> to ensure the model generalizes well.</li>
                </ul>
            </p>
        
            <h3>üìå Denoising Autoencoder</h3>
            <p>A <strong>denoising autoencoder</strong> removes noise from images by learning to reconstruct the original clean version.</p>
            <pre><code>
def add_noise(data, noise_factor=0.4):
    noisy_data = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
    return np.clip(noisy_data, 0., 1.)  # Ensure values remain between 0 and 1

# Generate noisy images
x_train_noisy = add_noise(x_train)
x_test_noisy = add_noise(x_test)

# Train denoising autoencoder
autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=256, validation_data=(x_test_noisy, x_test))
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>We <strong>add Gaussian noise</strong> to the images while keeping pixel values within [0,1].</li>
                    <li>The network <strong>learns to map noisy images back to clean images</strong>.</li>
                    <li>The denoising autoencoder <strong>forces the network to learn robust feature representations</strong>.</li>
                </ul>
            </p>

            <h3>üìå Summary</h3>
            <ul>
                <li>Built a <strong>basic autoencoder</strong> and trained it on <strong>MNIST</strong>.</li>
                <li>Implemented a <strong>denoising autoencoder</strong> to remove noise from images.</li>
                <li>Explored <strong>sparse autoencoders</strong>, which enforce sparsity in the latent representation.</li>
            </ul>
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
