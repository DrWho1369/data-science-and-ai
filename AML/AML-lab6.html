<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 6 - Deep Learning with Keras</title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header>
        <h1>AML Lab 6 - Deep Learning with Keras</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">‚Üê Back to Homepage</a>

        <section id="lab6">
            <h2>ü§ñ Lab 6: Deep Learning with Keras</h2>
            <p>This lab introduces <strong>Multi-Layer Perceptron (MLP) models</strong> using <strong>Keras</strong> with <strong>TensorFlow</strong> as the backend. We will cover defining, compiling, training, and evaluating deep learning models.</p>
        
            <h3>üìå Why Keras?</h3>
            <p>Keras is a <strong>high-level neural network API</strong> that allows easy model building while using powerful backend engines like TensorFlow. It is widely used for research and production due to its <strong>flexibility, ease of use, and strong industry adoption</strong>.</p>
        
            <h3>üìå Defining an MLP Model with Keras</h3>
            <p>The <strong>Sequential API</strong> allows us to define deep learning models in a layer-by-layer manner.</p>
            <pre><code>
        from keras.models import Sequential
        from keras.layers import Dense
        import numpy
        
        # Set random seed for reproducibility
        numpy.random.seed(7)
        
        # Define a simple feedforward MLP model
        model = Sequential()
        model.add(Dense(12, input_dim=8, activation='relu'))  # First hidden layer
        model.add(Dense(8, activation='relu'))  # Second hidden layer
        model.add(Dense(1, activation='sigmoid'))  # Output layer
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>The model consists of <strong>three layers</strong>: <strong>two hidden layers</strong> and <strong>one output layer</strong>.</li>
                    <li><code>input_dim=8</code> specifies that the input has <strong>8 features</strong>, which corresponds to the dataset‚Äôs input shape.</li>
                    <li><strong>ReLU (Rectified Linear Unit)</strong> is used in the hidden layers to introduce <strong>non-linearity</strong>, making it easier for the network to learn complex patterns.</li>
                    <li><strong>Sigmoid activation</strong> is used in the output layer because this is a <strong>binary classification problem</strong> (output between 0 and 1).</li>
                </ul>
            </p>
        
            <h3>üìå Alternative: Functional API</h3>
            <p>The Functional API allows more flexibility, supporting <strong>multiple inputs/outputs and complex architectures</strong>.</p>
            <pre><code>
        from keras import Input, Model
        
        input_layer = Input(shape=(8,))
        hidden_layer1 = Dense(12, activation='relu')(input_layer)
        hidden_layer2 = Dense(8, activation='relu')(hidden_layer1)
        output_layer = Dense(1, activation='sigmoid')(hidden_layer2)
        
        model = Model(inputs=input_layer, outputs=output_layer)
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>Uses <code>Input()</code> to define the <strong>input layer explicitly</strong>, which allows for <strong>custom model architectures</strong>.</li>
                    <li>Each layer <strong>connects independently</strong>, enabling <strong>shared layers, multiple inputs/outputs, or parallel processing</strong>.</li>
                </ul>
            </p>
        
            <h3>üìå Model Compilation</h3>
            <p>Before training, we <strong>compile the model</strong>, specifying the loss function, optimizer, and evaluation metric.</p>
            <pre><code>
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li><code>binary_crossentropy</code> is used for <strong>binary classification problems</strong> because it measures the difference between predicted probabilities and actual labels.</li>
                    <li><code>adam</code> (Adaptive Moment Estimation) is an <strong>advanced optimization algorithm</strong> that adapts the learning rate for better convergence.</li>
                    <li><code>accuracy</code> is used as a performance metric, tracking how often predictions match actual values.</li>
                </ul>
            </p>
        
            <h3>üìå Training the Model</h3>
            <p>We use the <strong>fit()</strong> function to train the model for 150 epochs.</p>
            <pre><code>
        model.fit(X, Y, epochs=150, batch_size=10)
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>Trains for <strong>150 epochs</strong>, meaning the dataset is passed through the model <strong>150 times</strong>.</li>
                    <li>Uses a <strong>batch size of 10</strong>, meaning weights are updated every <strong>10 samples</strong> instead of after every sample.</li>
                </ul>
            </p>
        
            <h3>üìå Model Evaluation</h3>
            <p>Evaluating model performance on <strong>unseen data</strong>.</p>
            <pre><code>
        scores = model.evaluate(X, Y)
        print(f"Accuracy: {scores[1]*100:.2f}%")
            </code></pre>
            <p><strong>Deep Explanation:</strong>
                <ul>
                    <li>The model is tested on unseen data to measure <strong>generalization performance</strong>.</li>
                    <li>Accuracy is reported as a percentage, showing how well the model performs.</li>
                    <li>However, using the <strong>same training data for evaluation can lead to overestimated performance</strong>‚Äîa separate test set should be used.</li>
                </ul>
            </p>
        
            <h3>üìå Summary</h3>
            <ul>
                <li>Built an <strong>MLP model</strong> using <strong>Keras Sequential and Functional API</strong>.</li>
                <li>Implemented <strong>cross-validation and validation sets</strong>.</li>
                <li>Applied <strong>saving/loading models</strong> for future use.</li>
            </ul>
        
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
