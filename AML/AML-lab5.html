<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 5 - Automating and Saving Models </title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header>
        <h1>AML Lab 5 - Automating and Saving Models</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">‚Üê Back to Homepage</a>

        <section id="lab5">
            <h2>‚öôÔ∏è Lab 5: Automating and Saving Models</h2>
            <p>Machine learning workflows often involve <strong>multiple steps</strong>, including data preparation, model training, evaluation, and deployment. This lab focuses on automating these steps using <strong>Pipelines</strong>, preventing <strong>data leakage</strong>, and <strong>saving trained models</strong> for future use.</p>
        
            <h3>üìå Using Pipelines in Scikit-Learn</h3>
            <p>Pipelines help <strong>combine preprocessing and model training</strong> into a single workflow, ensuring that data transformations only happen on the <strong>training set</strong> during cross-validation.</p>
            <pre><code>
from pandas import read_csv
from sklearn.model_selection import KFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# Load dataset
filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
data = read_csv(filename, names=names)

X = data.iloc[:, :-1]
Y = data.iloc[:, -1]

# Define pipeline steps
steps = [('standardize', StandardScaler()), ('lda', LinearDiscriminantAnalysis())]
model = Pipeline(steps)

# Evaluate pipeline with cross-validation
kfold = KFold(n_splits=10, random_state=7, shuffle=True)
results = cross_val_score(model, X, Y, cv=kfold)

print(f"Mean Accuracy: {results.mean():.3f}")
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>Pipelines <strong>automate preprocessing</strong> by ensuring transformations are applied correctly during training.</li>
                <li><code>Pipeline(steps)</code> chains transformations into a <strong>single reusable workflow</strong>, simplifying model development.</li>
                <li><code>cross_val_score</code> performs <strong>10-fold cross-validation</strong>, improving robustness by testing on different subsets.</li>
            </ul>
        
            <h3>üìå Extracting Model Coefficients</h3>
            <p>After training, we can <strong>extract model parameters</strong> like LDA coefficients to understand how features contribute to predictions.</p>
            <pre><code>
model.fit(X, Y)
lda_model = model.named_steps['lda']

print("LDA Coefficients:")
print(lda_model.coef_)
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>After fitting, we access the trained <strong>LDA model</strong> using <code>model.named_steps['lda']</code>.</li>
                <li><strong>LDA coefficients</strong> reveal how much each feature contributes to decision-making.</li>
            </ul>
        
            <h3>üìå Feature Engineering with FeatureUnion</h3>
            <p>FeatureUnion combines <strong>multiple feature selection techniques</strong> to improve model performance.</p>
            <pre><code>
from sklearn.pipeline import FeatureUnion
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest

# Define feature extraction methods
features = [('pca', PCA(n_components=3)), ('select_best', SelectKBest(k=6))]
feature_union = FeatureUnion(features)

# Create pipeline
pipeline_steps = [('feature_union', feature_union), ('logistic', LogisticRegression())]
model = Pipeline(pipeline_steps)

# Evaluate
results = cross_val_score(model, X, Y, cv=kfold)
print(f"Mean Accuracy: {results.mean():.3f}")
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><code>FeatureUnion</code> allows simultaneous <strong>dimensionality reduction (PCA) and feature selection (SelectKBest)</strong>.</li>
                <li>The final dataset is fed into a <strong>Logistic Regression model</strong> for classification.</li>
            </ul>
        
            <h3>üìå Saving and Loading Models</h3>
            <p>Machine learning models can be saved for <strong>future use</strong> using Pickle or Joblib.</p>
            <h4>Saving a Model with Pickle</h4>
            <pre><code>
import pickle

# Save model
with open('final_model.pkl', 'wb') as f:
    pickle.dump(model, f)

# Load model
with open('final_model.pkl', 'rb') as f:
    loaded_model = pickle.load(f)

print(loaded_model.predict(X[:5]))  # Predict using loaded model
            </code></pre>
            <h4>Saving a Model with Joblib</h4>
            <pre><code>
from joblib import dump, load

# Save
dump(model, 'final_model.joblib')

# Load
loaded_model = load('final_model.joblib')
print(loaded_model.predict(X[:5]))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><code>pickle</code> and <code>joblib</code> allow storing trained models for reuse.</li>
                <li><strong>Pickle</strong> is a general Python serialization tool, while <strong>Joblib</strong> is optimized for large numpy arrays.</li>
            </ul>
        
            <h3>üìå Summary</h3>
            <ul>
                <li><strong>Pipelines</strong> streamline ML workflows and <strong>prevent data leakage</strong>.</li>
                <li><strong>FeatureUnion</strong> combines multiple feature engineering techniques.</li>
                <li><strong>Bagging and Random Forests</strong> improve model performance using ensembles.</li>
                <li><strong>Hyperparameter tuning</strong> finds the best model configuration.</li>
                <li><strong>Saving models</strong> allows easy reuse without retraining.</li>
            </ul>
        
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
