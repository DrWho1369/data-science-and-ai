<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 7 - Convolutional Neural Networks (CNN) with Keras</title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header class="hero">
        <h1>AML Lab 7 - Convolutional Neural Networks (CNN) with Keras</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">‚Üê Back to Homepage</a>
        
        <section id="flashcards">
            <h2>Flashcards</h2>
            <div class="flashcard-container">
                <div class="flashcard" data-question="What is a Convolutional Neural Network (CNN)?" data-answer="A type of deep learning model designed for processing structured grid data, like images."></div>
                <div class="flashcard" data-question="What dataset is used in this lab?" data-answer="The MNIST dataset of handwritten digits (28x28 grayscale images)."></div>
                <div class="flashcard" data-question="How does the MNIST dataset help in deep learning?" data-answer="It is widely used as a benchmark for evaluating image classification models."></div>
                <div class="flashcard" data-question="What does the Conv2D layer do?" data-answer="It applies convolutional filters to extract features from an input image."></div>
                <div class="flashcard" data-question="Why do we use MaxPooling2D in a CNN?" data-answer="It reduces the spatial dimensions of feature maps, retaining important information while lowering computation cost."></div>
                <div class="flashcard" data-question="What is dropout in CNNs?" data-answer="A regularization technique that randomly ignores a fraction of neurons during training to prevent overfitting."></div>
                <div class="flashcard" data-question="How are images reshaped for CNN input?" data-answer="They are reshaped into a 4D tensor: (samples, height, width, channels), where channels = 1 for grayscale images."></div>
                <div class="flashcard" data-question="Why do we normalize pixel values?" data-answer="To scale them between 0 and 1, improving training stability and convergence."></div>
                <div class="flashcard" data-question="What is one-hot encoding, and why is it used?" data-answer="It converts categorical labels into binary vectors, ensuring compatibility with the neural network output layer."></div>
                <div class="flashcard" data-question="What activation function is used in CNN layers?" data-answer="ReLU (Rectified Linear Unit) is commonly used to introduce non-linearity."></div>
                <div class="flashcard" data-question="Why does the final layer use softmax activation?" data-answer="Softmax converts logits into probability distributions, allowing classification into multiple classes."></div>
                <div class="flashcard" data-question="What loss function is used for CNN classification?" data-answer="Categorical cross-entropy, which measures the difference between predicted and actual class probabilities."></div>
                <div class="flashcard" data-question="Why is the Adam optimizer commonly used in deep learning?" data-answer="It combines momentum and adaptive learning rate techniques, improving convergence speed."></div>
                <div class="flashcard" data-question="What does model.fit() do in Keras?" data-answer="It trains the model using the provided dataset, adjusting weights through backpropagation."></div>
                <div class="flashcard" data-question="What is the purpose of verbose in model training?" data-answer="It controls the amount of training information displayed during training (0: silent, 1: progress bar, 2: per-epoch output)."></div>
                <div class="flashcard" data-question="What is evaluated using model.evaluate()?" data-answer="The model‚Äôs loss and accuracy on test data."></div>
                <div class="flashcard" data-question="How do we visualize CNN training results?" data-answer="By plotting training and validation accuracy/loss across epochs using Matplotlib."></div>
                <div class="flashcard" data-question="How can misclassified images be identified?" data-answer="By comparing true labels and predicted labels, then displaying incorrectly classified images."></div>
                <div class="flashcard" data-question="How do we save a trained CNN model?" data-answer="Using model.save('model_name.h5') and later loading it with load_model()."></div>
            </div>
        </section>
        
        <section id="lab7">
            <h2>üñºÔ∏è Lab 7: Convolutional Neural Networks (CNN) with Keras</h2>
            <p><strong>Convolutional Neural Networks (CNNs)</strong> are a class of deep learning models designed for <strong>image classification and pattern recognition</strong>. Unlike traditional fully connected networks, CNNs extract <strong>spatial hierarchies of features</strong>, making them highly effective for visual data.</p>
        
            <h3>üìå Loading and Visualizing the MNIST Dataset</h3>
            <p>We begin by loading the <strong>MNIST handwritten digits dataset</strong>, which consists of <strong>60,000 training</strong> and <strong>10,000 test images</strong>.</p>
            <pre><code>
import keras
from keras.datasets import mnist
import matplotlib.pyplot as plt

# Load dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Display first 4 images
plt.figure(figsize=(6,6))
for i in range(4):
    plt.subplot(2,2,i+1)
    plt.imshow(x_train[i], cmap='gray')
    plt.axis('off')
plt.show()
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><strong>MNIST dataset</strong>: 28√ó28 pixel grayscale images representing digits 0-9.</li>
                <li>Each pixel intensity is between <strong>0 (black) and 255 (white)</strong>.</li>
                <li>Visualization helps confirm that data is loaded correctly.</li>
            </ul>
        
            <h3>üìå Preprocessing: Reshaping & Normalization</h3>
            <p>Before feeding images into a CNN, we must <strong>reshape and normalize</strong> them.</p>
            <pre><code>
img_rows, img_cols = 28, 28
input_shape = (img_rows, img_cols, 1)

# Reshape dataset to include a single grayscale channel
x_train = x_train.reshape(-1, img_rows, img_cols, 1)
x_test = x_test.reshape(-1, img_rows, img_cols, 1)

# Normalize pixel values to range [0,1]
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><strong>Reshaping:</strong> CNNs require an explicit <strong>channel dimension</strong> (1 for grayscale, 3 for RGB).</li>
                <li><strong>Normalization:</strong> Scaling values between <strong>0 and 1</strong> improves training efficiency and stability.</li>
            </ul>
        
            <h3>üìå Defining the CNN Model</h3>
            <p>The CNN consists of <strong>convolutional layers, pooling layers, and fully connected layers</strong>.</p>
            <pre><code>
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Define CNN architecture
model = Sequential()
model.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape, padding='same'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, kernel_size=(5,5), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Dropout(0.25))  # Reduce overfitting
model.add(Flatten())  # Convert 2D feature maps to a 1D vector
model.add(Dense(1000, activation='relu'))
model.add(Dropout(0.5))  # Further prevent overfitting
model.add(Dense(10, activation='softmax'))
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><strong>Conv2D:</strong> Applies filters to detect edges, textures, and patterns.</li>
                <li><strong>ReLU activation:</strong> Introduces non-linearity, allowing the model to learn complex features.</li>
                <li><strong>MaxPooling2D:</strong> Downsamples feature maps, reducing computational cost.</li>
                <li><strong>Flatten:</strong> Converts 2D feature maps into a 1D vector before passing them to dense layers.</li>
                <li><strong>Dropout:</strong> Prevents overfitting by randomly deactivating neurons during training.</li>
                <li><strong>Softmax output:</strong> Converts the final layer‚Äôs output into probability values for 10 digit classes.</li>
            </ul>
        
            <h3>üìå Compiling and Training the Model</h3>
            <p>We compile the model using the <strong>Adam optimizer</strong> and train it for <strong>12 epochs</strong>.</p>
            <pre><code>
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
history = model.fit(x_train, y_train, batch_size=128, epochs=12, validation_data=(x_test, y_test), verbose=1)
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><strong>Adam optimizer:</strong> Adaptive learning rate for efficient optimization.</li>
                <li><strong>Categorical cross-entropy:</strong> Used because we have <strong>multi-class classification (digits 0-9).</strong></li>
                <li><strong>Epochs:</strong> The dataset passes through the model 12 times.</li>
            </ul>
        
            <h3>üìå Evaluating Model Performance</h3>
            <p>We compute <strong>test accuracy</strong> to measure model performance.</p>
            <pre><code>
score = model.evaluate(x_test, y_test, verbose=0)
print(f"Test loss: {score[0]}")
print(f"Test accuracy: {score[1]*100:.2f}%")
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li>The model is tested on unseen data to measure generalization.</li>
                <li>Accuracy (%) is used as a key performance metric.</li>
            </ul>
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
