<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AML Lab 1 - Loading ML Data</title>
    <link rel="stylesheet" href="aml-styles.css">
</head>
<body>
    <header class="hero">
        <h1>AML Lab 1 - Loading ML Data</h1>
    </header>
    
    <main>
        <a href="AML-homepage.html" class="back-button">← Back to Homepage</a>

        <section id="lab1">
            <h2>🛠️ Lab 1: Loading Machine Learning Data</h2>
            <p>Properly loading data is the first crucial step in Machine Learning. This lab explores multiple ways to load data in Python, with a focus on <strong>CSV files</strong>. We use the <strong>Pima Indians Diabetes Dataset</strong>, which contains medical records used to predict diabetes.</p>
        
            <h3>📌 The Pima Indians Diabetes Dataset</h3>
            <p>This dataset contains <strong>768 observations</strong> and <strong>9 attributes</strong>, where the last column represents whether a patient developed diabetes (1) or not (0). The features include:</p>
            <ul>
                <li><strong>Pregnancies:</strong> Number of times pregnant</li>
                <li><strong>Plasma glucose:</strong> Plasma glucose concentration (2-hour test)</li>
                <li><strong>Blood Pressure:</strong> Diastolic blood pressure (mm Hg)</li>
                <li><strong>Skin Thickness:</strong> Triceps skin fold thickness (mm)</li>
                <li><strong>Insulin:</strong> 2-Hour serum insulin (mu U/ml)</li>
                <li><strong>BMI:</strong> Body mass index</li>
                <li><strong>Diabetes Pedigree:</strong> Diabetes pedigree function</li>
                <li><strong>Age:</strong> Patient age in years</li>
                <li><strong>Class:</strong> Outcome (1 = diabetes, 0 = no diabetes)</li>
            </ul>
        
            <h3>📌 Method 1: Loading CSV Using Python’s Standard Library</h3>
            <p>This method uses Python’s built-in <strong>csv</strong> module to read the dataset and convert it into a NumPy array.</p>
            <pre><code>
import csv
import numpy as np

filename = 'pima-indians-diabetes.data.csv'
raw_data = open(filename, 'rt')  # Open file in read mode
reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)  
data = np.array(list(reader)).astype('float')  # Convert to NumPy array
print("Dataset shape:", data.shape)
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><code>csv.reader</code> reads the CSV file line by line.</li>
                <li><code>delimiter=','</code> specifies that values are separated by commas.</li>
                <li><code>quoting=csv.QUOTE_NONE</code> prevents automatic type conversion.</li>
                <li><code>np.array()</code> converts the list into a NumPy array for numerical processing.</li>
            </ul>
        
            <h3>📌 Method 2: Loading CSV Using NumPy</h3>
            <p>NumPy provides a <strong>faster and simpler way</strong> to load numerical datasets.</p>
            <pre><code>
from numpy import loadtxt

filename = 'pima-indians-diabetes.data.csv'
data = loadtxt(filename, delimiter=',')
print("Dataset shape:", data.shape)
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><code>loadtxt()</code> directly reads the file into a NumPy array.</li>
                <li>This method is <strong>faster</strong> but only works if the dataset contains <strong>only numeric values</strong>.</li>
            </ul>
        
            <h3>📌 Method 3: Loading CSV from a URL</h3>
            <p>We can load datasets directly from the internet.</p>
            <pre><code>
from numpy import loadtxt
from urllib.request import urlopen

url = 'http://titan.dcs.bbk.ac.uk/~eveera01/aml/pima-indians-diabetes.data.csv'
raw_data = urlopen(url)
dataset = loadtxt(raw_data, delimiter=',')
print("Dataset shape:", dataset.shape)
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><code>urlopen(url)</code> downloads the dataset from a remote server.</li>
                <li>Ensure that the dataset is <strong>publicly accessible</strong> for this method to work.</li>
            </ul>
        
            <h3>📌 Method 4: Loading CSV Using Pandas</h3>
            <p>Pandas is the most <strong>flexible and powerful tool</strong> for working with data.</p>
            <pre><code>
import pandas as pd

filename = 'pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
data = pd.read_csv(filename, names=names)
print(data.shape)
            </code></pre>
            <p><strong>Deep Explanation:</strong></p>
            <ul>
                <li><code>pd.read_csv()</code> automatically handles missing values and column names.</li>
                <li>Pandas DataFrames make it <strong>easier to analyze and clean data</strong>.</li>
            </ul>
        
            <h3>📌 Exploratory Data Analysis</h3>
            <h4>🔹 Viewing the First Few Rows</h4>
            <pre><code>
print(data.head(20))  # Displays the first 20 rows
            </code></pre>
            <h4>🔹 Checking Dataset Dimensions</h4>
            <pre><code>
print(data.shape)  # Returns (rows, columns)
            </code></pre>
            <h4>🔹 Checking Data Types</h4>
            <pre><code>
print(data.dtypes)  # Shows types of each column
            </code></pre>
            <h4>🔹 Generating Summary Statistics</h4>
            <pre><code>
print(data.describe())  # Generates count, mean, std, min, and max
            </code></pre>
            <h4>🔹 Checking Class Distribution</h4>
            <pre><code>
print(data.groupby('class').size())  # Counts how many 0s and 1s in the dataset
            </code></pre>
        
            <h3>📌 Key Takeaways</h3>
            <ul>
                <li>There are multiple ways to load CSV data: <strong>csv.reader, NumPy, and Pandas</strong>.</li>
                <li>Pandas is the most flexible, allowing for <strong>data cleaning and visualization</strong>.</li>
                <li>Exploring datasets helps identify <strong>missing values, outliers, and class imbalances</strong>.</li>
            </ul>
        </section>
    </main>
    
    <footer>
        <p>&copy; 2025 Thomas Baker - MSc Data Science & AI Revision</p>
    </footer>
    
    <script defer src="aml-flashcards.js"></script>
</body>
</html>
